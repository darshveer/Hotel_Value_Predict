{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd7eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression , ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fed423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data \n",
    "processed_train_df = pd.read_csv(\"C:/Users/Mihir S Kagalkar/OneDrive - iiit-b/SEM-5/ML/PROJECT/jupyter_files/Processed_train_data.csv\")\n",
    "processed_test_df = pd.read_csv(\"C:/Users/Mihir S Kagalkar/OneDrive - iiit-b/SEM-5/ML/PROJECT/jupyter_files/Processed_test_data.csv\")\n",
    "train_df = train_df = pd.read_csv(\"C:/Users/Mihir S Kagalkar/OneDrive - iiit-b/SEM-5/ML/PROJECT/Hotel-Property-Value-Dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9f5e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores: [np.float64(86975.41183737198), np.float64(74199.07805518305), np.float64(71562.34749794248), np.float64(82811.00635794386), np.float64(89500.46124280611)]\n",
      "Mean RMSE: 81009.6609982495\n",
      "Std RMSE: 7022.314281913285\n"
     ]
    }
   ],
   "source": [
    "#initial tree+linear ridge model\n",
    "# --- PARAMETERS ---\n",
    "target_col = 'HotelValue'\n",
    "# ---------------------------------------\n",
    "# Separate features and target\n",
    "# ---------------------------------------\n",
    "X = processed_train_df.copy()\n",
    "y = train_df[target_col].values.reshape(-1, 1)\n",
    "\n",
    "# Scale target (stable regression at leaves)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaled = y_scaler.fit_transform(y).flatten()\n",
    "\n",
    "# Scale ALL features (numeric + categorical + PCA output)\n",
    "X_scaler = MinMaxScaler()\n",
    "X_scaled = X_scaler.fit_transform(X)\n",
    "\n",
    "# ---------------------------------------\n",
    "# K-Fold Decision Tree + Linear Regression at leaves\n",
    "# ---------------------------------------\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmse_scores = []\n",
    "# Hyperparameters (you can tune later)\n",
    "max_depth = 8\n",
    "min_samples_leaf = 100\n",
    "top_k_features = 10  # number of features allowed in leaf regression\n",
    "ridge_alpha = 1    # regularization strength\n",
    "\n",
    "for train_index, val_index in kf.split(X_scaled):\n",
    "    # Split fold\n",
    "    X_train_fold = X_scaled[train_index]\n",
    "    y_train_fold = y_scaled[train_index]\n",
    "    X_val_fold = X_scaled[val_index]\n",
    "    y_val_fold = y_scaled[val_index]\n",
    "\n",
    "    # Fit decision tree\n",
    "    tree = DecisionTreeRegressor(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    tree.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Get top-k important features\n",
    "    feat_idx_sorted = np.argsort(tree.feature_importances_)[::-1]\n",
    "    top_k_idx = feat_idx_sorted[:top_k_features]\n",
    "\n",
    "    # Train a regression model for each leaf\n",
    "    leaf_train_ids = tree.apply(X_train_fold)\n",
    "    leaf_models = {}\n",
    "\n",
    "    for leaf in np.unique(leaf_train_ids):\n",
    "        leaf_idx = np.where(leaf_train_ids == leaf)[0]\n",
    "        X_leaf = X_train_fold[leaf_idx][:, top_k_idx]\n",
    "        y_leaf = y_train_fold[leaf_idx]\n",
    "\n",
    "        # If leaf has too few samples â€” fallback to mean prediction\n",
    "        if X_leaf.shape[0] <= X_leaf.shape[1] + 2:\n",
    "            leaf_models[leaf] = (\"mean\", float(y_leaf.mean()))\n",
    "        else:\n",
    "            lr = Ridge(alpha=ridge_alpha)\n",
    "            lr.fit(X_leaf, y_leaf)\n",
    "            leaf_models[leaf] = (\"ridge\", lr)\n",
    "\n",
    "    # ---- Prediction ----\n",
    "    leaf_val_ids = tree.apply(X_val_fold)\n",
    "    y_pred_scaled = np.zeros_like(y_val_fold)\n",
    "\n",
    "    for i, leaf_id in enumerate(leaf_val_ids):\n",
    "        model_type, model = leaf_models.get(\n",
    "            leaf_id, (\"mean\", np.mean(y_train_fold))\n",
    "        )\n",
    "\n",
    "        if model_type == \"mean\":\n",
    "            y_pred_scaled[i] = model\n",
    "        else:\n",
    "            row = X_val_fold[i:i+1][:, top_k_idx]\n",
    "            y_pred_scaled[i] = model.predict(row)[0]\n",
    "\n",
    "    # Inverse-scale predicted y\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    y_true = y_scaler.inverse_transform(y_val_fold.reshape(-1, 1))\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "# Evaluation\n",
    "print(\"RMSE scores:\", rmse_scores)\n",
    "print(\"Mean RMSE:\", np.mean(rmse_scores))\n",
    "print(\"Std RMSE:\", np.std(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54d5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
